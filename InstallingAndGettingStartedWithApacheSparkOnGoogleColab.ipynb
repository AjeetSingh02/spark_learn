{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InstallingAndGettingStartedWithApacheSparkOnGoogleColab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNuxgS4VkfIgue7dU1DTZ4b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/spark_learn/blob/master/InstallingAndGettingStartedWithApacheSparkOnGoogleColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpVkHsnUHDBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1hFdOLdKeVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7cbaba7-d582-4eee-cf45-6771e51aab3d"
      },
      "source": [
        "!ls /usr/lib/jvm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4QzjCIeKxVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ecc1560e-cd75-429a-ab89-4987a7376dfc"
      },
      "source": [
        "# This installation is optional\n",
        "# This is useful when we want to convert spark df into pandas df\n",
        "# By default the conversion takes place by pickling and unpickling but thats quite slow\n",
        "# So to avoid that we will enable pyarrow to make things faster\n",
        "# Pandas and Spark both are pyarrow compatible so data gets transferred directly. no pickling\n",
        "! pip install pyarrow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (0.14.1)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDrR1EEHLmmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34U3Y70NHhjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()   # Will search for Spark and set in the system path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trhD_1OfMlPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to work with spark we need a spark context\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Here we are telling that SparkSession.builder.master is local since we dont have distributed environment\n",
        "# Both driver and executer node will be local colab environment\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Here we are providing other configurations which we usually provide during Spark Summit\n",
        "spark.conf.set(\"spark.executor.memory\", \"4g\")   # How much executer memory is allocated\n",
        "spark.conf.set(\"spark.driver.memory\", \"4g\")   # How much driver memory is allocated\n",
        "spark.conf.set(\"spark.memory.fraction\", \"0.9\")   # What memory fraction to allocate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Q2rs2vOazk",
        "colab_type": "text"
      },
      "source": [
        "We can provide other files too by this:\n",
        "\n",
        "For Jar files or any other submit arguments\n",
        "* os.environ['PYSPARK_SUBMIT_ARGS'] = \n",
        "\n",
        "To add python file in spark context\n",
        "* spark.sparkContext.addPyFile('../')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCksGIxEPRHc",
        "colab_type": "text"
      },
      "source": [
        "**Spark is installed. Now to test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSi1vz-aPtwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credit_df = spark.read.option(\"inferSchema\", \"true\").csv(\"/content/sample_data/california_housing_test.csv\", header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuTmp9LlQERh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "9cc5af40-39a6-417a-c8e7-8da580d3d04b"
      },
      "source": [
        "credit_df.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -122.05|   37.37|              27.0|     3885.0|         661.0|    1537.0|     606.0|       6.6085|          344700.0|\n",
            "|   -118.3|   34.26|              43.0|     1510.0|         310.0|     809.0|     277.0|        3.599|          176500.0|\n",
            "|  -117.81|   33.78|              27.0|     3589.0|         507.0|    1484.0|     495.0|       5.7934|          270500.0|\n",
            "|  -118.36|   33.82|              28.0|       67.0|          15.0|      49.0|      11.0|       6.1359|          330000.0|\n",
            "|  -119.67|   36.33|              19.0|     1241.0|         244.0|     850.0|     237.0|       2.9375|           81700.0|\n",
            "|  -119.56|   36.51|              37.0|     1018.0|         213.0|     663.0|     204.0|       1.6635|           67000.0|\n",
            "|  -121.43|   38.63|              43.0|     1009.0|         225.0|     604.0|     218.0|       1.6641|           67000.0|\n",
            "|  -120.65|   35.48|              19.0|     2310.0|         471.0|    1341.0|     441.0|        3.225|          166900.0|\n",
            "|  -122.84|    38.4|              15.0|     3080.0|         617.0|    1446.0|     599.0|       3.6696|          194400.0|\n",
            "|  -118.02|   34.08|              31.0|     2402.0|         632.0|    2830.0|     603.0|       2.3333|          164200.0|\n",
            "|  -118.24|   33.98|              45.0|      972.0|         249.0|    1288.0|     261.0|       2.2054|          125000.0|\n",
            "|  -119.12|   35.85|              37.0|      736.0|         166.0|     564.0|     138.0|       2.4167|           58300.0|\n",
            "|  -121.93|   37.25|              36.0|     1089.0|         182.0|     535.0|     170.0|         4.69|          252600.0|\n",
            "|  -117.03|   32.97|              16.0|     3936.0|         694.0|    1935.0|     659.0|       4.5625|          231200.0|\n",
            "|  -117.97|   33.73|              27.0|     2097.0|         325.0|    1217.0|     331.0|       5.7121|          222500.0|\n",
            "|  -117.99|   33.81|              42.0|      161.0|          40.0|     157.0|      50.0|          2.2|          153100.0|\n",
            "|  -120.81|   37.53|              15.0|      570.0|         123.0|     189.0|     107.0|        1.875|          181300.0|\n",
            "|   -121.2|   38.69|              26.0|     3077.0|         607.0|    1603.0|     595.0|       2.7174|          137500.0|\n",
            "|  -118.88|   34.21|              26.0|     1590.0|         196.0|     654.0|     199.0|       6.5851|          300000.0|\n",
            "|  -122.59|   38.01|              35.0|     8814.0|        1307.0|    3450.0|    1258.0|       6.1724|          414300.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_JNLW8QGox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b09f99ac-9180-4c99-a884-5bc68c178d94"
      },
      "source": [
        "credit_df.count()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}